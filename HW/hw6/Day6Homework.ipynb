{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question 2\n",
    "\n",
    "Write a function that converts Erik Durm's wikipedia page (the one we used in the [lecture](../Special-Topics/Web-Scraping.ipynb#Beautiful-Soup,-so-rich-and-green,-Waiting-in-a-hot-tureen!)) into a soup object and extracts the `<p>` element that starts with \"In the 2013–14 Bundesliga season...\". Your function must return the Beautiful Soup's `Tag` object itself.\n",
    "\n",
    "    def extract_bundesliga_p_tag(wiki_path):\n",
    "        '''\n",
    "        Extracts the <p> tag from ErikDurmWiki that starts with:\n",
    "        \"In the 2013-14 Bundesliga season.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        wiki_path : (str)\n",
    "            Path to Erik Durm's wikipedia page in the Data folder.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        p_tag : (bs4.element.tag)   \n",
    "            Beautiful Soup's tag object containing the paragraph in question.\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>In the 2013–14 Bundesliga season, Durm was inducted into Borussia Dortmund's first team and, on 10 August 2013, debuted for BVB in the Bundesliga; coming on in the 87th minute for <a href=\"/wiki/Robert_Lewandowski\" title=\"Robert Lewandowski\">Robert Lewandowski</a> as a substitute in BVB's 4–0 win over <a href=\"/wiki/FC_Augsburg\" title=\"FC Augsburg\">FC Augsburg</a>.<sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\"><span>[</span>11<span>]</span></a></sup><sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\"><span>[</span>12<span>]</span></a></sup> Durm debuted in the UEFA Champions League on 1 October 2013 in a 3–0 victory over French club Olympique Marseille.</p>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_bundesliga_p_tag(wiki_path):\n",
    "    '''\n",
    "    Extracts the <p> tag from ErikDurmWiki that starts with:\n",
    "    \"In the 2013-14 Bundesliga season.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    wiki_path : (str)\n",
    "        Path to Erik Durm's wikipedia page in the Data folder.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    p_tag : (bs4.element.tag)   \n",
    "        Beautiful Soup's tag object containing the paragraph in question.\n",
    "    '''\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    \n",
    "    with open(wiki_path, 'r') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "#         print(soup)\n",
    "        paragraphs = soup.findAll('p')\n",
    "        for paragraph in paragraphs:\n",
    "            if paragraph.getText().startswith('In the 2013–14 Bundesliga season'):\n",
    "                p_tag = paragraph\n",
    "    return p_tag\n",
    "\n",
    "extract_bundesliga_p_tag(\"erik_durm_wiki.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question 3\n",
    "\n",
    "In the Data folder you will find another previously scraped webpage containing the lyrics to Pink Floyd's Wish You Were Here: [Pink Floyd Lyrics](../Data/pink_floyd_wish.html)\n",
    "\n",
    "Write a function that converts this page into a soup and returns a list with the song's title and lyrics. Format the lyrics as a list of strings, with each string being a line in the lyrics. Remove all newline characters, empty lines, and html tags. \n",
    "Hint: You can use 'inspect element' to look at the source code for the lyrics in the above link\n",
    "\n",
    "    def extract_pink_floyd_lyrics(lyrics_path):\n",
    "        '''\n",
    "        Extracts the title and lyrics of Pink Floyd's Wish You Were Here song.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        lyrics_path : (str)\n",
    "            Path to the lyrics page in the Data folder.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        lyrics_info : (list)\n",
    "            List where the first element is the song's title (string)\n",
    "            and second element is a list of strings with the lyrics\n",
    "        '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Wish You Were Here',\n ['So, so you think you can tell Heaven from Hell, blue skies from pain.',\n  'Can you tell a green field from a cold steel rail?',\n  'A smile from a veil?',\n  'Do you think you can tell?',\n  'Did they get you to trade your heroes for ghosts?',\n  'Hot ashes for trees?',\n  'Hot air for a cool breeze?',\n  'Cold comfort for change?',\n  'Did you exchange a walk on part in the war for a lead role in a cage?',\n  'How I wish, how I wish you were here.',\n  \"We're just two lost souls swimming in a fish bowl, year after year,\",\n  'Running over the same old ground.',\n  'What have we found?',\n  'The same old fears.',\n  'Wish you were here.']]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_pink_floyd_lyrics(lyrics_path):\n",
    "    '''\n",
    "    Extracts the title and lyrics of Pink Floyd's Wish You Were Here song.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lyrics_path : (str)\n",
    "        Path to the lyrics page in the Data folder.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    lyrics_info : (list)\n",
    "        List where the first element is the song's title (string)\n",
    "        and second element is a list of strings with the lyrics\n",
    "    '''\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "\n",
    "    lyrics_info = []\n",
    "    with open(lyrics_path, 'r') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "    title = soup.find('div',class_='lyricsh').find_next('b').find_next('b').text\n",
    "    lyrics_info.append(title[1:-1])\n",
    "    lyrics = soup.find('div',class_='lyricsh').find_next('div').find_next('div').text\n",
    "    lyrics = lyrics.split('\\n')\n",
    "    #         lyrics = [x.split('\\n') for x in lyrics]\n",
    "    lyrics = [x for x in lyrics if x != '']\n",
    "    #         print(lyrics)\n",
    "    lyrics_info.append(lyrics)\n",
    "    return lyrics_info\n",
    "\n",
    "extract_pink_floyd_lyrics('pink_floyd_wish.html')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}